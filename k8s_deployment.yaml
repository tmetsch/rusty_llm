apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-deployment
  labels:
    app: ai-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-server
  template:
    metadata:
      labels:
        app: ai-server
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/path: '/metrics'
        prometheus.io/port: '8081'
    spec:
      containers:
        - name: ai-server
          image: rusty_llm:0.1.0
          ports:
            - containerPort: 8080
              name: server-port
          volumeMounts:
            - name: model-vol
              mountPath: /app/model
            - name: data-vol
              mountPath: /app/data
            - name: hf-cache-vol
              mountPath: /root/.cache/huggingface
          env:
            - name: MODEL_THREADS
              value: "2"
            - name: HTTP_ADDRESS
              value: "0.0.0.0:8080"
            - name: PROMETHEUS_HTTP_ADDRESS
              value: "0.0.0.0:8081"
          resources:
            requests:
              cpu: 2
              memory: 10Gi
            limits:
              cpu: 2
              memory: 10Gi
      volumes:
      - name: model-vol
        hostPath:
          path: /home/tmetsch/model
      - name: data-vol
        hostPath:
          path: /home/tmetsch/data
      - name: hf-cache-vol
        hostPath:
          path: /home/tmetsch/hf_cache
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  name: ai-service
spec:
  selector:
    app: ai-server
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 8080
  type: LoadBalancer